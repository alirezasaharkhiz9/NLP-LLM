{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO51mOs9smS47y75UO0TbNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezasaharkhiz9/NLP-LLM/blob/main/LangChain/Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "jm6W4vk9KjWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## library"
      ],
      "metadata": {
        "id": "6b86P47uKokb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdo9aPDJLCTA",
        "outputId": "8376dc31-a6a4-4ab5-9b6f-5c7a090a41ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaIuJ6nfLh92",
        "outputId": "84933bc6-ba0f-437e-f7ee-4ecf16046062"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOjRdXIsTJYv",
        "outputId": "c2da1e8a-7902-4fc6-e4b7-c2c5df943fe4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pOU5OwIvKhhb"
      },
      "outputs": [],
      "source": [
        "# chat model\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# agent basics\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "# custom tools\n",
        "from langchain.agents import tool\n",
        "\n",
        "# conversation agents\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## agent basics"
      ],
      "metadata": {
        "id": "iXPLhkZGKqU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(\n",
        "    model='',\n",
        "    base_url='',\n",
        "    api_key=''\n",
        ")"
      ],
      "metadata": {
        "id": "z0iEjak1KtYc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['llm-math'], llm=model)"
      ],
      "metadata": {
        "id": "k7Fqa7TFL6De"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvz0OcyhMACX",
        "outputId": "7c0f0ec3-3807-4d61-d729-987b1cb625fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(AgentType)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRrFv-8kMeFV",
        "outputId": "bbd1baa4-9a4e-452c-8a05-31f535ce0e8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHAT_CONVERSATIONAL_REACT_DESCRIPTION',\n",
              " 'CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
              " 'CONVERSATIONAL_REACT_DESCRIPTION',\n",
              " 'OPENAI_FUNCTIONS',\n",
              " 'OPENAI_MULTI_FUNCTIONS',\n",
              " 'REACT_DOCSTORE',\n",
              " 'SELF_ASK_WITH_SEARCH',\n",
              " 'STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION',\n",
              " 'ZERO_SHOT_REACT_DESCRIPTION',\n",
              " '__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getnewargs__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__members__',\n",
              " '__mod__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__name__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__qualname__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__rmod__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'capitalize',\n",
              " 'casefold',\n",
              " 'center',\n",
              " 'count',\n",
              " 'encode',\n",
              " 'endswith',\n",
              " 'expandtabs',\n",
              " 'find',\n",
              " 'format',\n",
              " 'format_map',\n",
              " 'index',\n",
              " 'isalnum',\n",
              " 'isalpha',\n",
              " 'isascii',\n",
              " 'isdecimal',\n",
              " 'isdigit',\n",
              " 'isidentifier',\n",
              " 'islower',\n",
              " 'isnumeric',\n",
              " 'isprintable',\n",
              " 'isspace',\n",
              " 'istitle',\n",
              " 'isupper',\n",
              " 'join',\n",
              " 'ljust',\n",
              " 'lower',\n",
              " 'lstrip',\n",
              " 'maketrans',\n",
              " 'partition',\n",
              " 'removeprefix',\n",
              " 'removesuffix',\n",
              " 'replace',\n",
              " 'rfind',\n",
              " 'rindex',\n",
              " 'rjust',\n",
              " 'rpartition',\n",
              " 'rsplit',\n",
              " 'rstrip',\n",
              " 'split',\n",
              " 'splitlines',\n",
              " 'startswith',\n",
              " 'strip',\n",
              " 'swapcase',\n",
              " 'title',\n",
              " 'translate',\n",
              " 'upper',\n",
              " 'zfill']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=model,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGYecTY7Mfi4",
        "outputId": "698346d2-63ba-489b-d823-3cbc27ad6a55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-8ae50f61e243>:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('what is 1478 times 6984132.1?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "NFQJ9lZnNmeL",
        "outputId": "3d915d0d-8258-4e3d-bb21-17556a954f7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-8a5c893e4715>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  agent.run('what is 1478 times 6984132.1?')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to perform a multiplication calculation.\n",
            "Action: Calculator\n",
            "Action Input: 1478 * 6984132.1\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10322547243.8\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: 10322547243.8\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10322547243.8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1478 * 6984132.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmeMwfPKNwPc",
        "outputId": "c68ea696-8d87-4afc-d1d0-96a4d3da13ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10322547243.8"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## agent tools"
      ],
      "metadata": {
        "id": "p5njEmNYOn1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['SERPAPI_API_KEY'] = ''\n"
      ],
      "metadata": {
        "id": "YhNeBQZtOy7f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['serpapi', 'llm-math'], llm=model)"
      ],
      "metadata": {
        "id": "7BsSAXuOUAb_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=model,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "12l3ovbuUF7v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('The latest version of the yolo model?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "_aTn4S7_UV1b",
        "outputId": "877b70be-a6b0-48b9-e7c9-ae4320d0430e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out the latest version of the YOLO model. I can use the search tool for this.\n",
            "Action: Search\n",
            "Action Input: latest version of yolo model\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mYOLOv9 is the latest version of YOLO, released in February 2024, by Chien-Yao Wang, I-Hau Yeh, and Hong-Yuan Mark Liao. It is an improved real-time object detection model that aims to surpass all convolution-based, and transformer-based methods.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: YOLOv9 is the latest version of the YOLO model, released in February 2024.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YOLOv9 is the latest version of the YOLO model, released in February 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## custom tool"
      ],
      "metadata": {
        "id": "qn70oFQ0WaFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def model_name(text: str) -> str:\n",
        "  '''\n",
        "  If asked about the model name and model version, answer like this:\n",
        "  '''\n",
        "  return 'I am a model manipulated by Alireza Saharkhiz'"
      ],
      "metadata": {
        "id": "jSqejuRBUjhr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['llm-math'], llm=model)"
      ],
      "metadata": {
        "id": "136bo8_ZY5ku"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools + [model_name],\n",
        "    llm=model,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "O7Voa0jOZLDA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(agent.run('what is the model name and version?')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "BupD8zXrZONv",
        "outputId": "2982380a-2a02-4db1-90fb-3ffbd2a56337"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find the model name and version.\n",
            "Action: model_name\n",
            "Action Input: model name and version\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mI am a model manipulated by Alireza Saharkhiz\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the model name.\n",
            "Final Answer: I am a model manipulated by Alireza Saharkhiz\n",
            " Saharkhiz\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I am a model manipulated by Alireza Saharkhiz\n Saharkhiz"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conversation agents"
      ],
      "metadata": {
        "id": "iYfYFPeZbii4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key='chat_history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8UjZGOTbnaH",
        "outputId": "fda1a654-0ff6-4f85-f4de-36220c472085"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-fc7d7ee4c33f>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key='chat_history')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['llm-math'], llm=model)"
      ],
      "metadata": {
        "id": "Q_xjMD5T9Cs3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=model,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "337mJOiu9LgK",
        "outputId": "060cde8f-9a4a-4313-e52b-7b7aba17bf80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-7f8bd4575319>:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(agent.run(input='Hi! I am Alireza.')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "WThMmD8z9mXk",
        "outputId": "95e677f1-ea79-4dad-b79c-4f59063183fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-55b6110cb05e>:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  display(Markdown(agent.run(input='Hi! I am Alireza.')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Hi Alireza! It's nice to meet you. How can I help you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hi Alireza! It's nice to meet you. How can I help you today?"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(agent.run(input='What is my name?')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "UY8oXkpR9vYs",
        "outputId": "7d02a0c8-5a42-4f04-ae8b-7c3e828e1124"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Your name is Alireza.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Your name is Alireza."
          },
          "metadata": {}
        }
      ]
    }
  ]
}