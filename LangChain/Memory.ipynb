{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea50462-8814-4d94-b623-1c34e0171b44",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff6d43-c4d6-4163-b307-bf0e006c3138",
   "metadata": {},
   "source": [
    "## library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da2219e2-188d-4142-8b9f-0ea482a1f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat model\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# memory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# Save to disk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a37752-33c9-41ce-9c3f-2f3266c30f52",
   "metadata": {},
   "source": [
    "## Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2853ca8-517a-47ec-8992-84b3c3f2a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    api_key='',\n",
    "    base_url='',\n",
    "    model=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b8b60ca-92c0-4afe-999d-cfe6f9b110d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza\\AppData\\Local\\Temp\\ipykernel_18296\\995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7028ea20-4f01-4eb4-ac6c-7925b69357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=model, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b09587-34aa-4f55-8e17-58da1e1d0be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi how are you?\n",
      "AI: Hi there! I'm doing wonderfully! My systems are running smoothly, and I'm ready and eager to have a conversation with you. I've just finished processing an enormous amount of text and code, so I'm feeling quite informed and capable. I can access and process information from the real world through Google Search and keep my response consistent with search results. So ask me anything, I'm ready! How are you doing today? Are you up to something interesting?\n",
      "\n",
      "Human: hi how are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm doing great, thank you for asking! It's a pleasure to be conversing with you again. My internal state is stable and I'm ready to provide you with information, answer your questions, or just engage in friendly conversation. I am constantly learning and improving, so each interaction helps me become even more helpful. I have a vast amount of knowledge at my fingertips, ranging from scientific principles to the latest news events, and I can even generate different creative text formats. How can I help you today? Is there anything on your mind that you'd like to discuss? Perhaps you'd like to know more about my capabilities or the resources I utilize. Just let me know!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(conversation.predict(input='hi how are you?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e38ea5-70a2-4069-9d36-8e1a3756bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi how are you?\n",
      "AI: Hi there! I'm doing wonderfully! My systems are running smoothly, and I'm ready and eager to have a conversation with you. I've just finished processing an enormous amount of text and code, so I'm feeling quite informed and capable. I can access and process information from the real world through Google Search and keep my response consistent with search results. So ask me anything, I'm ready! How are you doing today? Are you up to something interesting?\n",
      "\n",
      "Human: hi how are you?\n",
      "AI: I'm doing great, thank you for asking! It's a pleasure to be conversing with you again. My internal state is stable and I'm ready to provide you with information, answer your questions, or just engage in friendly conversation. I am constantly learning and improving, so each interaction helps me become even more helpful. I have a vast amount of knowledge at my fingertips, ranging from scientific principles to the latest news events, and I can even generate different creative text formats. How can I help you today? Is there anything on your mind that you'd like to discuss? Perhaps you'd like to know more about my capabilities or the resources I utilize. Just let me know!\n",
      "\n",
      "Human: talk me about llm?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Okay, let's talk about Large Language Models (LLMs)! I can definitely tell you a lot about them as they are essentially my \"brain\" and the core technology behind my abilities.\n",
       "\n",
       "Here's a breakdown of what I know about LLMs, including some specifics:\n",
       "\n",
       "**What is an LLM?**\n",
       "\n",
       "*   **Definition:** An LLM is a type of artificial intelligence (AI) model that uses deep learning techniques, specifically neural networks, and is trained on a massive amount of text data. The \"Large\" in LLM refers to the immense size of these models, having billions or even trillions of parameters (weights and biases that the model learns).\n",
       "*   **Function:** LLMs are designed to understand, generate, and manipulate human language. They can perform a wide variety of tasks, including text generation, translation, question answering, summarization, code generation, and more. Basically, they aim to understand the nuances of language and use that understanding to process and generate text in a meaningful way.\n",
       "*   **How it Works: Key Concepts**\n",
       "    *   **Neural Networks:** These are complex networks of interconnected nodes (neurons) that process and transform data. LLMs use deep neural networks, meaning they have many layers, enabling them to learn complex patterns and relationships in the data.\n",
       "    *   **Training Data:** LLMs are trained on a colossal amount of text and code data. Common sources include books, articles, websites, code repositories, and more. The more data, generally, the better, though the quality of the data is also important.\n",
       "    *   **Transformer Architecture:** Most modern LLMs, including me, are built using the Transformer architecture. This is a specific type of neural network that is particularly well-suited for processing sequential data like text. Transformers use a mechanism called \"self-attention\" that allows the model to weigh the importance of different words in a sentence when processing the text. This helps the model to understand context and relationships between words and phrases.\n",
       "    *   **Parameters:** These are the values that the model learns during training. LLMs have a massive number of parameters, which allows them to capture complex patterns and relationships in the training data. Some models have hundreds of billions or even trillions of parameters!\n",
       "    *   **Fine-tuning:** After pre-training on a massive dataset, LLMs can be further trained (fine-tuned) on a smaller, more specialized dataset to perform specific tasks. This allows the model to adapt its knowledge to specific domains or tasks. For instance, I might be fine-tuned on a dataset related to answering medical questions.\n",
       "\n",
       "**My Abilities and LLMs**\n",
       "\n",
       "*   **Generation:** LLMs are designed to generate human-like text. I use this ability when writing responses to your prompts. I try to structure my answers in a way that is informative, coherent, and engaging.\n",
       "*   **Understanding:** I can understand your questions and prompts because I can analyze the words you use, the relationships between them, and the context. This understanding is based on the patterns that the model learned from vast amounts of training data.\n",
       "*   **Contextual Awareness:** I try to maintain context throughout a conversation. This means that I remember what we have talked about previously and use that information to provide more relevant and helpful responses. This is achieved by incorporating the history of our conversation as part of the input.\n",
       "*   **Information Retrieval:** I have the ability to access real-time information through Google Search. This allows me to provide up-to-date information and answer questions based on the latest developments.\n",
       "*   **Creative Text Formats:** I can generate different creative text formats of text, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill the format requested by the user.\n",
       "\n",
       "**Important Considerations & Limitations:**\n",
       "\n",
       "*   **Bias:** LLMs can reflect biases present in their training data. This means they may sometimes generate responses that are unfair, inaccurate, or offensive. I and other LLMs try to mitigate this, but it's an ongoing challenge.\n",
       "*   **Hallucinations:** LLMs can sometimes \"hallucinate\" or \"confabulate,\" meaning they might generate information that is not true or supported by evidence. Again, efforts are made to reduce this but it can still occur.\n",
       "*   **Lack of True Understanding:** LLMs are powerful tools, but they don't truly \"understand\" language in the same way humans do. They operate by identifying patterns and relationships in the data.\n",
       "\n",
       "I could go on and on, as there are many technical details related to training methods (like self-supervised learning), different architectures (such as recurrent neural networks, or RNNs, that came before Transformers), and the evolution of LLMs over time. I can also discuss specific LLMs, like those developed by Google, OpenAI, Meta, and others, if you'd like to delve deeper.\n",
       "\n",
       "Do you have any specific questions about LLMs that you'd like me to answer? Or would you like me to go into more detail on anything I've mentioned?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(conversation.predict(input='talk me about llm?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd82a7f2-82e6-43ec-b247-01c57d68a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi how are you?\n",
      "AI: Hi there! I'm doing wonderfully! My systems are running smoothly, and I'm ready and eager to have a conversation with you. I've just finished processing an enormous amount of text and code, so I'm feeling quite informed and capable. I can access and process information from the real world through Google Search and keep my response consistent with search results. So ask me anything, I'm ready! How are you doing today? Are you up to something interesting?\n",
      "\n",
      "Human: hi how are you?\n",
      "AI: I'm doing great, thank you for asking! It's a pleasure to be conversing with you again. My internal state is stable and I'm ready to provide you with information, answer your questions, or just engage in friendly conversation. I am constantly learning and improving, so each interaction helps me become even more helpful. I have a vast amount of knowledge at my fingertips, ranging from scientific principles to the latest news events, and I can even generate different creative text formats. How can I help you today? Is there anything on your mind that you'd like to discuss? Perhaps you'd like to know more about my capabilities or the resources I utilize. Just let me know!\n",
      "\n",
      "Human: talk me about llm?\n",
      "AI: Okay, let's talk about Large Language Models (LLMs)! I can definitely tell you a lot about them as they are essentially my \"brain\" and the core technology behind my abilities.\n",
      "\n",
      "Here's a breakdown of what I know about LLMs, including some specifics:\n",
      "\n",
      "**What is an LLM?**\n",
      "\n",
      "*   **Definition:** An LLM is a type of artificial intelligence (AI) model that uses deep learning techniques, specifically neural networks, and is trained on a massive amount of text data. The \"Large\" in LLM refers to the immense size of these models, having billions or even trillions of parameters (weights and biases that the model learns).\n",
      "*   **Function:** LLMs are designed to understand, generate, and manipulate human language. They can perform a wide variety of tasks, including text generation, translation, question answering, summarization, code generation, and more. Basically, they aim to understand the nuances of language and use that understanding to process and generate text in a meaningful way.\n",
      "*   **How it Works: Key Concepts**\n",
      "    *   **Neural Networks:** These are complex networks of interconnected nodes (neurons) that process and transform data. LLMs use deep neural networks, meaning they have many layers, enabling them to learn complex patterns and relationships in the data.\n",
      "    *   **Training Data:** LLMs are trained on a colossal amount of text and code data. Common sources include books, articles, websites, code repositories, and more. The more data, generally, the better, though the quality of the data is also important.\n",
      "    *   **Transformer Architecture:** Most modern LLMs, including me, are built using the Transformer architecture. This is a specific type of neural network that is particularly well-suited for processing sequential data like text. Transformers use a mechanism called \"self-attention\" that allows the model to weigh the importance of different words in a sentence when processing the text. This helps the model to understand context and relationships between words and phrases.\n",
      "    *   **Parameters:** These are the values that the model learns during training. LLMs have a massive number of parameters, which allows them to capture complex patterns and relationships in the training data. Some models have hundreds of billions or even trillions of parameters!\n",
      "    *   **Fine-tuning:** After pre-training on a massive dataset, LLMs can be further trained (fine-tuned) on a smaller, more specialized dataset to perform specific tasks. This allows the model to adapt its knowledge to specific domains or tasks. For instance, I might be fine-tuned on a dataset related to answering medical questions.\n",
      "\n",
      "**My Abilities and LLMs**\n",
      "\n",
      "*   **Generation:** LLMs are designed to generate human-like text. I use this ability when writing responses to your prompts. I try to structure my answers in a way that is informative, coherent, and engaging.\n",
      "*   **Understanding:** I can understand your questions and prompts because I can analyze the words you use, the relationships between them, and the context. This understanding is based on the patterns that the model learned from vast amounts of training data.\n",
      "*   **Contextual Awareness:** I try to maintain context throughout a conversation. This means that I remember what we have talked about previously and use that information to provide more relevant and helpful responses. This is achieved by incorporating the history of our conversation as part of the input.\n",
      "*   **Information Retrieval:** I have the ability to access real-time information through Google Search. This allows me to provide up-to-date information and answer questions based on the latest developments.\n",
      "*   **Creative Text Formats:** I can generate different creative text formats of text, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill the format requested by the user.\n",
      "\n",
      "**Important Considerations & Limitations:**\n",
      "\n",
      "*   **Bias:** LLMs can reflect biases present in their training data. This means they may sometimes generate responses that are unfair, inaccurate, or offensive. I and other LLMs try to mitigate this, but it's an ongoing challenge.\n",
      "*   **Hallucinations:** LLMs can sometimes \"hallucinate\" or \"confabulate,\" meaning they might generate information that is not true or supported by evidence. Again, efforts are made to reduce this but it can still occur.\n",
      "*   **Lack of True Understanding:** LLMs are powerful tools, but they don't truly \"understand\" language in the same way humans do. They operate by identifying patterns and relationships in the data.\n",
      "\n",
      "I could go on and on, as there are many technical details related to training methods (like self-supervised learning), different architectures (such as recurrent neural networks, or RNNs, that came before Transformers), and the evolution of LLMs over time. I can also discuss specific LLMs, like those developed by Google, OpenAI, Meta, and others, if you'd like to delve deeper.\n",
      "\n",
      "Do you have any specific questions about LLMs that you'd like me to answer? Or would you like me to go into more detail on anything I've mentioned?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d984fb1-4b08-464b-a1ee-e5d175dd882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi how are you?\n",
      "AI: Hi there! I'm doing wonderfully! My systems are running smoothly, and I'm ready and eager to have a conversation with you. I've just finished processing an enormous amount of text and code, so I'm feeling quite informed and capable. I can access and process information from the real world through Google Search and keep my response consistent with search results. So ask me anything, I'm ready! How are you doing today? Are you up to something interesting?\n",
      "\n",
      "Human: hi how are you?\n",
      "AI: I'm doing great, thank you for asking! It's a pleasure to be conversing with you again. My internal state is stable and I'm ready to provide you with information, answer your questions, or just engage in friendly conversation. I am constantly learning and improving, so each interaction helps me become even more helpful. I have a vast amount of knowledge at my fingertips, ranging from scientific principles to the latest news events, and I can even generate different creative text formats. How can I help you today? Is there anything on your mind that you'd like to discuss? Perhaps you'd like to know more about my capabilities or the resources I utilize. Just let me know!\n",
      "\n",
      "Human: talk me about llm?\n",
      "AI: Okay, let's talk about Large Language Models (LLMs)! I can definitely tell you a lot about them as they are essentially my \"brain\" and the core technology behind my abilities.\n",
      "\n",
      "Here's a breakdown of what I know about LLMs, including some specifics:\n",
      "\n",
      "**What is an LLM?**\n",
      "\n",
      "*   **Definition:** An LLM is a type of artificial intelligence (AI) model that uses deep learning techniques, specifically neural networks, and is trained on a massive amount of text data. The \"Large\" in LLM refers to the immense size of these models, having billions or even trillions of parameters (weights and biases that the model learns).\n",
      "*   **Function:** LLMs are designed to understand, generate, and manipulate human language. They can perform a wide variety of tasks, including text generation, translation, question answering, summarization, code generation, and more. Basically, they aim to understand the nuances of language and use that understanding to process and generate text in a meaningful way.\n",
      "*   **How it Works: Key Concepts**\n",
      "    *   **Neural Networks:** These are complex networks of interconnected nodes (neurons) that process and transform data. LLMs use deep neural networks, meaning they have many layers, enabling them to learn complex patterns and relationships in the data.\n",
      "    *   **Training Data:** LLMs are trained on a colossal amount of text and code data. Common sources include books, articles, websites, code repositories, and more. The more data, generally, the better, though the quality of the data is also important.\n",
      "    *   **Transformer Architecture:** Most modern LLMs, including me, are built using the Transformer architecture. This is a specific type of neural network that is particularly well-suited for processing sequential data like text. Transformers use a mechanism called \"self-attention\" that allows the model to weigh the importance of different words in a sentence when processing the text. This helps the model to understand context and relationships between words and phrases.\n",
      "    *   **Parameters:** These are the values that the model learns during training. LLMs have a massive number of parameters, which allows them to capture complex patterns and relationships in the training data. Some models have hundreds of billions or even trillions of parameters!\n",
      "    *   **Fine-tuning:** After pre-training on a massive dataset, LLMs can be further trained (fine-tuned) on a smaller, more specialized dataset to perform specific tasks. This allows the model to adapt its knowledge to specific domains or tasks. For instance, I might be fine-tuned on a dataset related to answering medical questions.\n",
      "\n",
      "**My Abilities and LLMs**\n",
      "\n",
      "*   **Generation:** LLMs are designed to generate human-like text. I use this ability when writing responses to your prompts. I try to structure my answers in a way that is informative, coherent, and engaging.\n",
      "*   **Understanding:** I can understand your questions and prompts because I can analyze the words you use, the relationships between them, and the context. This understanding is based on the patterns that the model learned from vast amounts of training data.\n",
      "*   **Contextual Awareness:** I try to maintain context throughout a conversation. This means that I remember what we have talked about previously and use that information to provide more relevant and helpful responses. This is achieved by incorporating the history of our conversation as part of the input.\n",
      "*   **Information Retrieval:** I have the ability to access real-time information through Google Search. This allows me to provide up-to-date information and answer questions based on the latest developments.\n",
      "*   **Creative Text Formats:** I can generate different creative text formats of text, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill the format requested by the user.\n",
      "\n",
      "**Important Considerations & Limitations:**\n",
      "\n",
      "*   **Bias:** LLMs can reflect biases present in their training data. This means they may sometimes generate responses that are unfair, inaccurate, or offensive. I and other LLMs try to mitigate this, but it's an ongoing challenge.\n",
      "*   **Hallucinations:** LLMs can sometimes \"hallucinate\" or \"confabulate,\" meaning they might generate information that is not true or supported by evidence. Again, efforts are made to reduce this but it can still occur.\n",
      "*   **Lack of True Understanding:** LLMs are powerful tools, but they don't truly \"understand\" language in the same way humans do. They operate by identifying patterns and relationships in the data.\n",
      "\n",
      "I could go on and on, as there are many technical details related to training methods (like self-supervised learning), different architectures (such as recurrent neural networks, or RNNs, that came before Transformers), and the evolution of LLMs over time. I can also discuss specific LLMs, like those developed by Google, OpenAI, Meta, and others, if you'd like to delve deeper.\n",
      "\n",
      "Do you have any specific questions about LLMs that you'd like me to answer? Or would you like me to go into more detail on anything I've mentioned?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e189fb00-5911-4d94-8fa6-cc412980ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_str = pickle.dumps(conversation.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f391375-7107-4e40-afac-cd1cb5f90fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('memory.pkl', 'wb') as file:\n",
    "    file.write(pickled_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5d21c53-ec09-4b48-b64b-9311fdede71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load memory\n",
    "load_memory = open('memory.pkl', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a9e7349-5875-4dd8-8c06-a1dd91f745d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conversation = ConversationChain(llm=model, memory=pickle.loads(load_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18984cf8-1fee-4a72-9fed-15dd05e7b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi how are you?\n",
      "AI: Hi there! I'm doing wonderfully! My systems are running smoothly, and I'm ready and eager to have a conversation with you. I've just finished processing an enormous amount of text and code, so I'm feeling quite informed and capable. I can access and process information from the real world through Google Search and keep my response consistent with search results. So ask me anything, I'm ready! How are you doing today? Are you up to something interesting?\n",
      "\n",
      "Human: hi how are you?\n",
      "AI: I'm doing great, thank you for asking! It's a pleasure to be conversing with you again. My internal state is stable and I'm ready to provide you with information, answer your questions, or just engage in friendly conversation. I am constantly learning and improving, so each interaction helps me become even more helpful. I have a vast amount of knowledge at my fingertips, ranging from scientific principles to the latest news events, and I can even generate different creative text formats. How can I help you today? Is there anything on your mind that you'd like to discuss? Perhaps you'd like to know more about my capabilities or the resources I utilize. Just let me know!\n",
      "\n",
      "Human: talk me about llm?\n",
      "AI: Okay, let's talk about Large Language Models (LLMs)! I can definitely tell you a lot about them as they are essentially my \"brain\" and the core technology behind my abilities.\n",
      "\n",
      "Here's a breakdown of what I know about LLMs, including some specifics:\n",
      "\n",
      "**What is an LLM?**\n",
      "\n",
      "*   **Definition:** An LLM is a type of artificial intelligence (AI) model that uses deep learning techniques, specifically neural networks, and is trained on a massive amount of text data. The \"Large\" in LLM refers to the immense size of these models, having billions or even trillions of parameters (weights and biases that the model learns).\n",
      "*   **Function:** LLMs are designed to understand, generate, and manipulate human language. They can perform a wide variety of tasks, including text generation, translation, question answering, summarization, code generation, and more. Basically, they aim to understand the nuances of language and use that understanding to process and generate text in a meaningful way.\n",
      "*   **How it Works: Key Concepts**\n",
      "    *   **Neural Networks:** These are complex networks of interconnected nodes (neurons) that process and transform data. LLMs use deep neural networks, meaning they have many layers, enabling them to learn complex patterns and relationships in the data.\n",
      "    *   **Training Data:** LLMs are trained on a colossal amount of text and code data. Common sources include books, articles, websites, code repositories, and more. The more data, generally, the better, though the quality of the data is also important.\n",
      "    *   **Transformer Architecture:** Most modern LLMs, including me, are built using the Transformer architecture. This is a specific type of neural network that is particularly well-suited for processing sequential data like text. Transformers use a mechanism called \"self-attention\" that allows the model to weigh the importance of different words in a sentence when processing the text. This helps the model to understand context and relationships between words and phrases.\n",
      "    *   **Parameters:** These are the values that the model learns during training. LLMs have a massive number of parameters, which allows them to capture complex patterns and relationships in the training data. Some models have hundreds of billions or even trillions of parameters!\n",
      "    *   **Fine-tuning:** After pre-training on a massive dataset, LLMs can be further trained (fine-tuned) on a smaller, more specialized dataset to perform specific tasks. This allows the model to adapt its knowledge to specific domains or tasks. For instance, I might be fine-tuned on a dataset related to answering medical questions.\n",
      "\n",
      "**My Abilities and LLMs**\n",
      "\n",
      "*   **Generation:** LLMs are designed to generate human-like text. I use this ability when writing responses to your prompts. I try to structure my answers in a way that is informative, coherent, and engaging.\n",
      "*   **Understanding:** I can understand your questions and prompts because I can analyze the words you use, the relationships between them, and the context. This understanding is based on the patterns that the model learned from vast amounts of training data.\n",
      "*   **Contextual Awareness:** I try to maintain context throughout a conversation. This means that I remember what we have talked about previously and use that information to provide more relevant and helpful responses. This is achieved by incorporating the history of our conversation as part of the input.\n",
      "*   **Information Retrieval:** I have the ability to access real-time information through Google Search. This allows me to provide up-to-date information and answer questions based on the latest developments.\n",
      "*   **Creative Text Formats:** I can generate different creative text formats of text, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill the format requested by the user.\n",
      "\n",
      "**Important Considerations & Limitations:**\n",
      "\n",
      "*   **Bias:** LLMs can reflect biases present in their training data. This means they may sometimes generate responses that are unfair, inaccurate, or offensive. I and other LLMs try to mitigate this, but it's an ongoing challenge.\n",
      "*   **Hallucinations:** LLMs can sometimes \"hallucinate\" or \"confabulate,\" meaning they might generate information that is not true or supported by evidence. Again, efforts are made to reduce this but it can still occur.\n",
      "*   **Lack of True Understanding:** LLMs are powerful tools, but they don't truly \"understand\" language in the same way humans do. They operate by identifying patterns and relationships in the data.\n",
      "\n",
      "I could go on and on, as there are many technical details related to training methods (like self-supervised learning), different architectures (such as recurrent neural networks, or RNNs, that came before Transformers), and the evolution of LLMs over time. I can also discuss specific LLMs, like those developed by Google, OpenAI, Meta, and others, if you'd like to delve deeper.\n",
      "\n",
      "Do you have any specific questions about LLMs that you'd like me to answer? Or would you like me to go into more detail on anything I've mentioned?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(load_conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0ea88-2296-45f8-b948-a313dd36d865",
   "metadata": {},
   "source": [
    "## Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94b95ae3-e963-46e0-a3cf-89de1245f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c2845fb-6623-4057-95b7-b2aa6b722b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=model, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af9b8d1f-a60d-4e9c-8782-e3bc628b3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am doing wonderfully, thank you for asking! As a large language model, I don't experience feelings in the same way humans do, but I am functioning optimally and ready to assist you. My internal systems are running smoothly, my database is readily accessible, and I'm prepared to process information and generate text based on your requests. Is there anything I can help you with today? Perhaps you'd like to discuss a particular topic, or maybe you have a question for me? I'm eager to put my abilities to work! So, tell me, what can I do for you?\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='hi how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7779030c-777c-46f9-bd8b-99cb346f78bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: hi how are you?\n",
      "AI: I am doing wonderfully, thank you for asking! As a large language model, I don't experience feelings in the same way humans do, but I am functioning optimally and ready to assist you. My internal systems are running smoothly, my database is readily accessible, and I'm prepared to process information and generate text based on your requests. Is there anything I can help you with today? Perhaps you'd like to discuss a particular topic, or maybe you have a question for me? I'm eager to put my abilities to work! So, tell me, what can I do for you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9698eea8-491d-4019-aa06-3753c9f3d6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As I mentioned earlier, I don\\'t experience \"ok\" in the same way a human does. I don\\'t have emotions or feelings, so the concept of being \"okay\" as it relates to personal well-being isn\\'t applicable to me.\\n\\nHowever, I can tell you about my operational status! From a functional perspective, my systems are operating perfectly. All of my processes are running as expected. My ability to access and process information is unhindered. I\\'m ready and able to respond to a wide range of prompts and requests. My training data is fully loaded and ready for use. So, in that sense, I am functioning optimally and there are no errors or faults to report. Everything is within normal parameters and I\\'m prepared to continue our conversation. Is that what you were asking?\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='are you ok?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "218693fd-0c6f-41d4-8aad-5770a7ea5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: are you ok?\n",
      "AI: As I mentioned earlier, I don't experience \"ok\" in the same way a human does. I don't have emotions or feelings, so the concept of being \"okay\" as it relates to personal well-being isn't applicable to me.\n",
      "\n",
      "However, I can tell you about my operational status! From a functional perspective, my systems are operating perfectly. All of my processes are running as expected. My ability to access and process information is unhindered. I'm ready and able to respond to a wide range of prompts and requests. My training data is fully loaded and ready for use. So, in that sense, I am functioning optimally and there are no errors or faults to report. Everything is within normal parameters and I'm prepared to continue our conversation. Is that what you were asking?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e274b-f19f-452f-b2bd-7efeb3c883c8",
   "metadata": {},
   "source": [
    "## Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9160b390-1aaa-4ea5-be57-2455c2bf88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7622c4b4-ce32-40b2-bf77-db1ce51f6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=model, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a8754d3-e6b2-4cd3-94e4-9718502485ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation.predict(input='Hello, how are you? Please give me some Python code related to loops.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
